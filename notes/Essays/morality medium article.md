# How I Think About Morality (A Rational Basis For Caring About People)

:::caution Unfinished

This is a work-in-progress.

As of Sep 19, 2022, this is almost done. I've decided not to go super in-depth on all the different moral theories as that would be beside the point I'm trying to make. I might do that in future essays, though. 

:::

Often times when discussing politics, I've found that there are disagreements that can be difficult to resolve, even when we agree on the facts. What I've found is that many of these disagreements boil down to the ethical assumptions that each of us are using to reach our conclusions. In order to know what a "good" policy, behavior, or economic system is, we first have to define "good". In this article, I will attempt to explain how I come to my conclusions about morality, and how this affects my worldview.

Below are examples of some of my views. Some of these, you may agree with, and others you may find strange or unconventional. In order to understand them, you must understand my moral philosophy:

- No sentient being should ever be made to suffer unless there is no way around it. Unnecessary pain and suffering includes: animals in factory farms, "enhanced interrogation", poverty, harsh forms of punishment, etc. This also includes [wild animals who constantly suffer](https://www.animal-ethics.org/wild-animal-suffering-section/wild-animal-suffering-matters/) from malnutrition, disease, harsh weather conditions, and more.
- Retributive "justice" is _never_ a reason to harm someone. (Punishment which prevents future harm, however, can be.)
- Markets, government, hierarchy (including workplace hierarchy), and wealth inequality are not inherently unethical, although any of these taken to an extreme will usually result in unnecessary suffering, and I think that in the future we could see all of these things eliminated or transformed entirely.
- A techno-utopian future where humans are [super-intelligent, free of despair, and have the option to live forever](https://www.youtube.com/watch?v=bTMS9y8OVuY), is a desirable goal.

## A quote on suffering

This is a quote from one of my favorite philosophers that beautifully summarizes the moral reasoning that I'm about to dive into:

> Let's say I find myself in agony because my hand is on a hot stove. That agony is intrinsically motivating, even if my conviction that I ought to withdraw my hand doesn't follow the formal canons of logical inference.
>
> If one takes the scientific world-picture seriously, then there is nothing ontologically special or privileged about here-and-now or me - the egocentric illusion is a trick of perspective engineered by selfish DNA.
>
> If it's wrong for me to be in agony, then it is wrong for anyone, anywhere.
>
> - David Pearce
>   ([Source](https://www.abolitionist.com))

In the following sections, I will use two premises to reach the conculsion that we should care about the well-being of all sentient creatures.

## Premise 1: My well-being matters.

![Saturday Morning Breakfast Cereal - 2013-08-15](https://pbs.twimg.com/profile_banners/1263894994726711298/1590175037/1500x500)

Before arguing that all suffering is wrong, I find it easiest to start with the claim that _my own_ suffering is wrong. This is different from saying that I don't like to suffer-- that would be an "is" statement (describing facts of the matter)--here I am making an "ought" statement, that my well-being _should_ be protected.

Right off the bat, I'll say that this is an [axiom](https://en.wikipedia.org/wiki/Axiom)--a premise that I have an intuition about, but have not proven to be true. I can't make a rational argument that my own well-being is important in a way that properly bridges the [is-ought gap](https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem), however this is one of my most deeply-held beliefs, and not believing this would lead to an absurd existance where any action done towards me, no matter how harmful, could be morally neutral or justified. I cannot imagine an existence where this axiom is not true.

In philosophy, arguments sometimes have to start from unjustified premises, and unfortunately this is one of those cases. However, I don't think this is a controversial claim (maybe some people don't think that _my_ well-being matters, but they can just substitute themselves into the claim instead and hopefully they'd agree). I find the next premise more interesting, and I hope the logic from this point forward makes a clear case for my thesis.

<!--**TODO: Flesh out this section**-->

<!--
- We could try to justify this with Chalmers' panpsychism/dualism: If our minds are not merely physical, we can justify extending greater care towards them than other physical (non-sentient) objects. But this isn't a full argument, and it doesn't bridge the is-ought gap, because it doesn't tell us *why* something being non-physical means we should care about it.
- We could also try to say that my well-being matters because well-being = good, but that would fail to bridge the is-ought gap.
- Ultimately, what I know is that I view my own well-being as something of moral worth. If I am harmed by someone, I believe more than anything in the world that I have been wronged.
- This is a foundational axiom that I cannot justify, but one could argue that all knowledge is built upon these types of axioms. There has to be some things that we just take for granted, and being that this is my most deeply-held belief, for me this has to be one of those things.
	- It's the simplest axiom I could have chosen to start with

-->

## Premise 2: I don't matter more than anyone else.

We've established that my well-being matters, yet as I've said, I don't have a reason for why that is. However, by eliminating some potential reasons, we can arrive at another realization.

- _My well-being matters because I'm human._
  - This claim might feel natural, because we generally tend to recognize humans as members of society, as moral agents, and as people who deserve well-being. But I haven't seen a good argument as to why being human necessarily means I deserve well-being any more than if I were a different species that had its own thoughts and feelings.

- _My well-being matters because I'm me._
  - Ethical egoism argues that what is morally right is defined by each person fulfilling their own desires. Essentially, if you want something, then it's ethical for you to have it.
  - Of course, if our goal is for a moral system to be _objective_, it must be consistent. So this can't possibly work. People are going to have competing interests, and if our moral system says that everyone must pursue their interests, it's going to have contradictions when different people want different things. Thus, ethical egoism is insufficient grounds for arguing that my well-being matters.

- _My well-being matters because I'm a good person._
  - There is no good argument for saying that [people who act well deserve better than people who act badly](https://plato.stanford.edu/entries/desert/#Justice), especially if we accept determinism-- the belief that we don't really make any of our own choices.
  - The argument that creating this type of society is good because it benefits people is circular reasoning-- you first have to define what is good.

We've eliminated all potential reasons that separate me from others to justify my well-being. I still don't know what the reason is that my well-being matters, but this process of elimination has led me to the conclusion that, if I ever do find a justification for my own well-being, it would likely justify everyone's well-being. In other words:

## Conclusion: Everyone's well-being matters.

Because there is no rational way to justify my own well-being above others, yet I know that my own well-being is ethically significant, I must conclude that everyone's well-being matters. If I ever do find a rational justification for Premise 1, I would expect that argument to also logically follow for everyone who isn't me. Furthermore, if someone wanted to argue for **moral nihilism** (the idea that well-being doesn't matter), they would have to denounce Premise 1 and state that *their own* well-being doesn't matter. The adherence to this claim could be tested by placing the person's hand on a hot stove.

Another way to wrap your head around this concept is to use a thought experiment referred to by John Rawls as the "[veil of ignorance](https://en.wikipedia.org/wiki/Original_position)". Imagine that you are about to be born into the world, and you have no idea what country you will live in, what your social status will be, or even what species you will belong to. Now try to construct a world where, regardless of where these circumstances land, you will be able to propser and live a good life. This way of thinking ensures that you are considering everyone's well-being when making moral decisions.

We've answered the basic question of why we should care about others, and why we should create a world where everyone (specifically, every living thing that is capable of having **well-being**) can prosper. But what are the rammifications of this? What should we actually do with this information? This is where we turn to moral philosophy. There are many different philosophies around [how to be moral](https://en.wikipedia.org/wiki/Ethics), [what well-being even means](https://plato.stanford.edu/entries/well-being/), [how we value pain vs. pleasure](https://en.wikipedia.org/wiki/Suffering-focused_ethics), whether or not we have [free will](https://en.wikipedia.org/wiki/Determinism) and [how that impacts moral responsibility](https://plato.stanford.edu/entries/moral-responsibility/), and much more. It's a huge field with lots of debate and discussion on all of the different issues. 

However, even without delving into philosophy and wrestling with all of these difficult questions, there are some basic prescriptions we can make once we accept that everyone's well-being matters.

<!--**TODO: Write more on each of these bullet points**

Questions to determine which moral theories we hold true (Most of these use [consequentialism](https://plato.stanford.edu/entries/consequentialism/) as a basis):

- Do we define well-being as the conscious experience of pleasure and pain, or do we define it as a satisfaction of individual preferences?
  - Hedonistic vs preference utiltarianism
  - I personally choose preference utilitarianism to make my decisions, however for a very long time I believed in hedonistic utilitarianism. This is because, personally, the things I value in life only boil down to subjective conscious experience (see below for examples). I changed my position after realizing that, while my assumption is that this is the case for others as well (and that other values, such as autonomy, honesty, loyalty, etc, are simply means to an end), I have no way of proving that this is true. If I lived in a world where everyone was a clone of me, I would still be a hedonistic utilitarian. But I don't think that view is compatible with society.
  - Personally, I'm hedonistic
    - Talk about The Hedonistic Imperative, which I view as a noble technological goal that I would very much enjoy, but shouldn't be forced onto everyone
    - Experience machine
    - World-ending button
    - It seems like this is the view that Sam Harris holds, although I don't believe he's made any effective arguments in its favor.
    - Examples of my own hedonism: ignorance is bliss (wouldn't mind being [talked about behind my back](https://www.reddit.com/r/askphilosophy/comments/393bqd/is_there_any_reason_its_considered_worse_to_talk/), am not scared of death, would want to live in the [experience machine](https://en.wikipedia.org/wiki/Experience_machine), am sympatheic to [anti-natalist](https://en.wikipedia.org/wiki/Antinatalism) arguments)
  - However, I can't prove that everyone else also hedonistic, which leads me to preference utilitarianism
- Classical vs negative utilitarianism
  - Prioritarianism
  - Sufficientarianism
- Total vs average utilitarianism
  - Repugnant conclusion
- Rights-based theories
- Rawls' Justice as Fairness
  - Tbh I'm not well-versed on his overall theory, but I like his "veil of ignorance" concept and I think this applies to many of the other theories mentioned
- After a while, I stopped caring about the exact math or what equations I should be using. What's important, especially given my limited time and energy, is that my actions contribute to the reduction of suffering in some way
- I have never in my life seen a moral system that doesn't result in some hypothetical dilemmas (classical utilitarianism is full of them, by the way), and even if I did find a moral system that was devoid of any uncomfortable conclusions, it would most likely disagree with the fundamental axioms that I laid out at the beginning of my argument.
- I'll say the same thing for philosophy as I will for any other academic subject: **If the answer was simple, most of the experts would agree.**-->

## Contributing to everyone's well-being
It follows from my argument that everyone should contribute to making the world a better place for all living organisms, as long as they can do so without causing themselves great harm. In case you're still not convinced of this, consider the "drowning child" thought experiment:

> To challenge my students to think about the ethics of what we owe to people in need, I ask them to imagine that their route to the university takes them past a shallow pond. One morning, I say to them, you notice a child has fallen in and appears to be drowning. To wade in and pull the child out would be easy but it will mean that you get your clothes wet and muddy, and by the time you go home and change you will have missed your first class.
> 
> I then ask the students: do you have any obligation to rescue the child? Unanimously, the students say they do. The importance of saving a child so far outweighs the cost of getting one’s clothes muddy and missing a class, that they refuse to consider it any kind of excuse for not saving the child. Does it make a difference, I ask, that there are other people walking past the pond who would equally be able to rescue the child but are not doing so? No, the students reply, the fact that others are not doing what they ought to do is no reason why I should not do what I ought to do.
> 
> Once we are all clear about our obligations to rescue the drowning child in front of us, I ask: would it make any difference if the child were far away, in another country perhaps, but similarly in danger of death, and equally within your means to save, at no great cost – and absolutely no danger – to yourself? Virtually all agree that distance and nationality make no moral difference to the situation. I then point out that we are all in that situation of the person passing the shallow pond: we can all save lives of people, both children and adults, who would otherwise die, and we can do so at a very small cost to us: the cost of a new CD, a shirt or a night out at a restaurant or concert, can mean the difference between life and death to more than one person somewhere in the world – and overseas aid agencies like Oxfam overcome the problem of acting at a distance.
> 
> - Peter Singer ([Source](https://newint.org/features/1997/04/05/peter-singer-drowning-child-new-internationalist))

That said, it can be stressful to think about all the suffering in the world and in our own communities and how to even begin to address it. It's easy to feel hopeless that your efforts will actually accomplish anything, because you're only one person, and the world is a harsh place with many ongoing problems.

However, the truth is that we each have an impact on the world through our actions every day, from immediate actions such as greeting someone with a smile or giving a few dollars to a person experiencing houselessness, to indirect actions such as participating in the economy, voting in elections, donating to a cause, or creating art.

The question is, how do we do the most with our contributions? Peter Singer, who created the thought experiment above, inspired a movement called [Effective Altruism](https://www.effectivealtruism.org), which advocates "maximizing the good you can do" through charitable donations and lifestyle choices such as veganism. It's affiliated with a charity evaluation organization called [GiveWell](https://www.givewell.org), which conducts rigorous research on organizations that save the most lives per dollar. There is an [online community](https://forum.effectivealtruism.org) of effective altruists who are constantly discussing and organizing on ways to do the most good, which is filled with lots of brilliant ideas and back-and-forth debates. And over the past decade, the movement has grown to [raise billions of dollars](https://www.vox.com/future-perfect/2022/8/8/23150496/effective-altruism-sam-bankman-fried-dustin-moskovitz-billionaire-philanthropy-crytocurrency) to preventing diseases, transferring cash to people in extreme poverty, mitigating existential risks, and protecting animal welfare. Thousands of individuals have signed the [Giving What We Can](https://www.givingwhatwecan.org) pledge to donate at least 10% of their income to effective charities, and you can [sign up here](https://www.givingwhatwecan.org) if you're interested.

Not everyone agrees that Effective Altruism is the best movement for doing good. It's [FAQ page](https://www.effectivealtruism.org/faqs-criticism-objections#objectionsto-effective-altruism) lists some common critiques, such as that it doesn't focus enough on systemic issues that could make a bigger difference in the long term. In addition, some scholars [reject charity in general](https://www.vox.com/future-perfect/2018/12/17/18141181/foundation-charity-deduction-democracy-rob-reich) as being undemocratic. [Others disagree](https://slatestarcodex.com/2019/07/29/against-against-billionaire-philanthropy/), and I think that GiveWell does a [tremendous job](https://www.givewell.org/research) of evaluating which organizations truly save the most lives. But if that's not the road you want to go down, there are plenty of other ways to make a difference in the world. You can volunteer with an organization that you're passionate about, vote with your dollar by making ethical purchases, get involved with local politics, engage in good-faith discussions about current issues, and so much more. My goal is not to convince you that there's a specific way that you should be giving back to the world (or that you shouldn't prioritize your own health and well-being-- you absolutely should), but just to demonstrate that you should care about others, there's no good reason to be a [nihilist](https://en.wikipedia.org/wiki/Moral_nihilism), and there are measurable ways to do good in the world. Wherever you are in life, I hope that this inspires you to do the most that you can!