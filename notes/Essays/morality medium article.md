# How I Think About Morality (A Rational Basis For Caring About People)

:::caution Unfinished

This is a work-in-progress.

I've made it publicly available in its current state because you may find it interesting. Eventually I'll finish and formally publish it, but I'm not sure when that will be.

:::

<!--
- I think there is a certain logic lacking in people's moral discussions (freedom, justice, fairness, etc)
- Am I about to make a Sam Harris argument about morality being "objective" and "scientific"? Maybe, but I'm hoping this article will be more nuanced
-->

Often times when discussing politics, I've found that there are disagreements that can be difficult to resolve, even when we agree on the facts. What I've found is that many of these disagreements boil down to the ethical assumptions that each of us are using to reach our conclusions. In order to know what a "good" policy, behavior, or economic system is, we first have to define "good". In this article, I will attempt to explain how I come to my conclusions about morality, and how this affects my worldview.

Below are examples of some of my views. Some of these, you may agree with, and others you may find strange or unconventional. In order to understand them, you must understand my moral philosophy:

- No sentient being should ever be made to suffer unless there is no way around it. Unnecessary pain and suffering includes: animals in factory farms, circumcision, "enhanced interrogation", poverty, harsh forms of punishment, etc. This also includes [wild animals who constantly suffer](https://www.animal-ethics.org/wild-animal-suffering-section/wild-animal-suffering-matters/) from malnutrition, disease, harsh weather conditions, and more.
- Retributive "justice" is _never_ a reason to harm someone. (Punishment which prevents future harm, however, can be.)
- Markets, government, hierarchy (including workplace hierarchy), and wealth inequality are not inherently unethical, although any of these taken to an extreme will usually result in unnecessary suffering, and I'm not against a future world where some or all of these things have been eliminated or transformed entirely.
- A techno-utopian future where humans are [super-intelligent, free of despair, and have the option to live forever](https://www.youtube.com/watch?v=bTMS9y8OVuY), is a desirable goal.

## A quote on suffering

This is a quote from one of my favorite philosophers that beautifully summarizes the moral reasoning that I'm about to dive into:

> Let's say I find myself in agony because my hand is on a hot stove. That agony is intrinsically motivating, even if my conviction that I ought to withdraw my hand doesn't follow the formal canons of logical inference.
>
> If one takes the scientific world-picture seriously, then there is nothing ontologically special or privileged about here-and-now or me - the egocentric illusion is a trick of perspective engineered by selfish DNA.
>
> If it's wrong for me to be in agony, then it is wrong for anyone, anywhere.
>
> - David Pearce
>   ([Source](https://www.abolitionist.com))

In the following sections, I will use two premises to reach the conculsion that we should care about the well-being of all sentient creatures.

## Premise 1: My well-being matters.

![Saturday Morning Breakfast Cereal - 2013-08-15](https://pbs.twimg.com/profile_banners/1263894994726711298/1590175037/1500x500)

Before arguing that all suffering is wrong, I find it easiest to start with the claim that _my own_ suffering is wrong. This is different from saying that I don't like to suffer-- that would be an "is" statement (describing facts of the matter)--here I am making an "ought" statement, that my well-being _should_ be protected.

Right off the bat, I'll say that this is an [axiom](https://en.wikipedia.org/wiki/Axiom)--a premise that I have an intuition about, but have not proven to be true. I can't make a rational argument that my own well-being is important in a way that properly bridges the [is-ought gap](https://en.wikipedia.org/wiki/Is%E2%80%93ought_problem), however this is one of my most deeply-held beliefs, and not believing this would lead to an absurd existance where any action done towards me, no matter how harmful, could be morally neutral or justified. I cannot imagine an existence where this axiom is not true.

In philosophy, arguments sometimes have to start from unjustified premises, and unfortunately this is one of those cases. However, I don't think this is a controversial claim (maybe some people don't think that _my_ well-being matters, but they can just substitute themselves into the claim instead and hopefully they'd agree). I find the next premise more interesting, and I hope the logic from this point forward makes a clear case for my thesis.

**TODO: Flesh out this section**

<!--
- We could try to justify this with Chalmers' panpsychism/dualism: If our minds are not merely physical, we can justify extending greater care towards them than other physical (non-sentient) objects. But this isn't a full argument, and it doesn't bridge the is-ought gap, because it doesn't tell us *why* something being non-physical means we should care about it.
- We could also try to say that my well-being matters because well-being = good, but that would fail to bridge the is-ought gap.
- Ultimately, what I know is that I view my own well-being as something of moral worth. If I am harmed by someone, I believe more than anything in the world that I have been wronged.
- This is a foundational axiom that I cannot justify, but one could argue that all knowledge is built upon these types of axioms. There has to be some things that we just take for granted, and being that this is my most deeply-held belief, for me this has to be one of those things.
	- It's the simplest axiom I could have chosen to start with

-->

## Premise 2: I don't matter more than anyone else.

We've established that my well-being matters, yet as I've said, I don't have a reason for why that is. However, by eliminating some potential reasons, we can arrive at another realization.

- _My well-being matters because I'm human._

  - This claim might feel natural, because we generally tend to recognize humans as members of society, as moral agents, and as people who deserve well-being. But I haven't seen a good argument as to why being human necessarily means I deserve well-being any more than if I were a different species.

- _My well-being matters because I'm me._

  - Ethical egoism argues that what is morally right is defined by each person fulfilling their own desires. Essentially, if you want something, then it's ethical for you to have it.
  - Of course, if our goal is for a moral system to be _objective_, it must be consistent. So this can't possibly work. People are going to have competing interests, and if our moral system says that everyone must pursue their interests, it's going to have contradictions when different people want different things. Thus, ethical egoism is insufficient grounds for arguing that my well-being matters.

- _My well-being matters because I'm a good person._
  - There is also no good argument for saying that [people who act well deserve better than people who act badly](https://plato.stanford.edu/entries/desert/#Justice), particularly if we accept determinism-- the belief that we don't really make any of our own choices.
  - The argument that creating this type of society is good because it benefits people is circular reasoning-- you first have to define what is good.

We've eliminated all potential reasons that separate me from others to justify my well-being. I still don't know what the reason is that my well-being matters, but this process of elimination has led me to the conclusion that, if I ever do find a justification for my own well-being, it would likely justify everyone's well-being. In other words:

## Conclusion: Everyone's well-being matters.

Because there is no rational way to justify my own well-being above others, yet I know that my own well-being is ethically significant, I must conclude that everyone's well-being matters. If I ever do find a rational justification for Premise 1, I would expect that argument to also logically follow for everyone who isn't me. Furthermore, if someone wanted to argue for **moral nihilism** (the idea that well-being doesn't matter), they would have to denounce Premise 1 and state that *their own* well-being doesn't matter. The adherence to this claim could be tested by placing the person's hand on a hot stove. ;) 

This answers the basic question of why we should care about others, and why we should create a world where everyone (specifically, every living thing that is capable of having **well-being**) can prosper. But what are the rammifications of this? What should we actually do with this information?

This is where we turn to moral philosophy. There are many different philosophies around [how to be moral](https://en.wikipedia.org/wiki/Ethics), [the meaning of well-being](https://plato.stanford.edu/entries/well-being/), whether or not we have [free will](https://en.wikipedia.org/wiki/Determinism) and [how that impacts moral responsibility](https://plato.stanford.edu/entries/moral-responsibility/), and much more. I'm not interested in delving into these at the moment, as none of them have clear-cut answers. That said, I have opinions on all of them that I may share in future essays.

<!--**TODO: Write more on each of these bullet points**

Questions to determine which moral theories we hold true (Most of these use [consequentialism](https://plato.stanford.edu/entries/consequentialism/) as a basis):

- Do we define well-being as the conscious experience of pleasure and pain, or do we define it as a satisfaction of individual preferences?
  - Hedonistic vs preference utiltarianism
  - I personally choose preference utilitarianism to make my decisions, however for a very long time I believed in hedonistic utilitarianism. This is because, personally, the things I value in life only boil down to subjective conscious experience (see below for examples). I changed my position after realizing that, while my assumption is that this is the case for others as well (and that other values, such as autonomy, honesty, loyalty, etc, are simply means to an end), I have no way of proving that this is true. If I lived in a world where everyone was a clone of me, I would still be a hedonistic utilitarian. But I don't think that view is compatible with society.
  - Personally, I'm hedonistic
    - Talk about The Hedonistic Imperative, which I view as a noble technological goal that I would very much enjoy, but shouldn't be forced onto everyone
    - Experience machine
    - World-ending button
    - It seems like this is the view that Sam Harris holds, although I don't believe he's made any effective arguments in its favor.
    - Examples of my own hedonism: ignorance is bliss (wouldn't mind being [talked about behind my back](https://www.reddit.com/r/askphilosophy/comments/393bqd/is_there_any_reason_its_considered_worse_to_talk/), am not scared of death, would want to live in the [experience machine](https://en.wikipedia.org/wiki/Experience_machine), am sympatheic to [anti-natalist](https://en.wikipedia.org/wiki/Antinatalism) arguments)
  - However, I can't prove that everyone else also hedonistic, which leads me to preference utilitarianism
- Classical vs negative utilitarianism
  - Prioritarianism
  - Sufficientarianism
- Total vs average utilitarianism
  - Repugnant conclusion
- Rights-based theories
- Rawls' Justice as Fairness
  - Tbh I'm not well-versed on his overall theory, but I like his "veil of ignorance" concept and I think this applies to many of the other theories mentioned
- After a while, I stopped caring about the exact math or what equations I should be using. What's important, especially given my limited time and energy, is that my actions contribute to the reduction of suffering in some way
- I have never in my life seen a moral system that doesn't result in some hypothetical dilemmas (classical utilitarianism is full of them, by the way), and even if I did find a moral system that was devoid of any uncomfortable conclusions, it would most likely disagree with the fundamental axioms that I laid out at the beginning of my argument.
- I'll say the same thing for philosophy as I will for any other academic subject: **If the answer was simple, most of the experts would agree.**-->

## How to live as a consequentialist

- Effective Altruism
- Veganism
- Don't seek other people's suffering (e.g. revenge)

## Further reading

- [David Pearce's excellent essay about negative hedonistic utilitarianism](https://www.hedweb.com/hedethic/hedon2.htm)
- https://www.utilitarianism.com/nu/nufaq.html
- https://www.abolitionist.com
- https://en.wikipedia.org/wiki/Original_position
- [Theories of well-being](https://plato.stanford.edu/entries/well-being/)
- https://reducing-suffering.org/three-types-of-negative-utilitarianism/
